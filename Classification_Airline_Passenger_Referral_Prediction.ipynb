{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "mDgbUHAGgjLW",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "yiiVWRdJDDil",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "ArJBuiUVfxKd",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aayusharma01/ML-Project/blob/main/Classification_Airline_Passenger_Referral_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -Airline Passenger Referral Prediction\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Classification\n",
        "##### **Contribution**    - Individual\n",
        "##### ** Member Name**    - Aayush Sharma"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the summary here within 500-600 words.\n",
        "\n",
        "Data includes airline reviews from 2006 to 2019 for popular airlines around the world with multiple choice and free text questions. Data is scraped in Spring 2019. The main objective is to predict whether passengers will refer the airline to their friends.. My project aims to address this issue by leveraging a combination of data analysis, visualization, feature engineering, ensemble techniques, and machine learning algorithms with parameter tuning to provide a more precise and consistent prediction of customer referral to their friend."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/aayusharma01/ML-Project"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Write Problem Statement Here.**\n",
        "\n",
        "The primary objective of this project is to build a machine learning model that can accurately predict whether passengers are likely to recommend the airline to their friends."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***\n",
        "\n"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_loc = '/content/data_airline_reviews.xlsx'"
      ],
      "metadata": {
        "id": "Dm7XDf_dkaQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "\n",
        "import lightgbm\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import LinearSVC\n",
        "import time\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "metadata": {
        "id": "q0U7wv42gt5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing  metrics for evaluation for our models\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from sklearn.metrics import accuracy_score,precision_score\n",
        "from sklearn.metrics import recall_score,f1_score,roc_curve, roc_auc_score"
      ],
      "metadata": {
        "id": "9mFIRnhPg0Ta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(dataset_loc)"
      ],
      "metadata": {
        "id": "QqG6TUh_lfE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_view = df.head()\n",
        "first_view"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "id": "T7rMrivJgrxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "rows_col_count = df.shape\n",
        "rows_col_count"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "infor_abt_data = df.info()\n",
        "infor_abt_data"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#copy the dataframe so that original dataframe won't be affected\n",
        "df1 =df.copy()"
      ],
      "metadata": {
        "id": "88nK17zNVRrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "\n",
        "duplicate_counts = df1.duplicated().sum()\n",
        "\n",
        "# Display the count of duplicates\n",
        "print(f\"Number of duplicates:{duplicate_counts}\")"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dropping Duplicate Values\n",
        "df1.drop_duplicates(inplace = True)"
      ],
      "metadata": {
        "id": "O4w3E8knlxjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Count of remaining rows and Columns\n",
        "df1.shape"
      ],
      "metadata": {
        "id": "UND83fall73k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "missi_value = df1.isnull().sum().sort_values(ascending=False)[:10]\n",
        "missi_value"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "# Plot a bar chart\n",
        "plt.figure(figsize=(10, 6),facecolor='skyblue')\n",
        "missi_value.plot(kind='bar', color='pink')\n",
        "\n",
        "# Set labels and title\n",
        "plt.title(\"Missing Values\")\n",
        "plt.xlabel(\"Columns\")\n",
        "plt.ylabel(\"Missing Value Count\")"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Airline Passenger referral prediction dataset contains aircraft name,complete passenger review,date flown,cabin service,type of seat,seat comfort which gives airline owners a prediction whether passengers will recommend the particular airline to their friend or not after doing brief data Analysis and applying several Machine Learning algorithms."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df1.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df1.info()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.describe().T"
      ],
      "metadata": {
        "id": "9YAwtwgyItnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "uniq_valu ={}\n",
        "for column in df1.columns:\n",
        "  uniq_valu = df1[column].unique()\n",
        "  print(f\"Unique values for {column}:\")\n",
        "  print(uniq_valu)"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Dropping missing values\n",
        "df1 = df1.dropna(subset=['cabin_service','recommended','ground_service','overall','value_for_money','seat_comfort'])\n",
        "\n",
        "#Dropping unnecessary columns that are of no use in data Visualization as well as ML model\n",
        "df1 =df1.drop(['author','review_date','route','date_flown','customer_review','aircraft'],axis = 1)\n",
        "#Splitting the Numeric column\n",
        "low_null = ['overall','seat_comfort','cabin_service','value_for_money']\n",
        "high_null = ['food_bev','entertainment',]\n",
        "\n",
        "\n",
        "#Imputation technique using Quantile-1 value\n",
        "def impute_by_q1_values(df1,column):\n",
        "  Q1=np.percentile(np.sort(df[column].dropna()),25)\n",
        "  df[column].fillna(Q1,inplace=True)\n",
        "\n",
        "\n",
        "#Looping the null value column\n",
        "for col in low_null:\n",
        "  impute_by_q1_values(df1,col)\n",
        "\n",
        "\n",
        "#Imputation technique using Median Imputation\n",
        "def median_imputation(df1,column):\n",
        "  df1[column].fillna(df1[column].median(),inplace=True)\n",
        "\n",
        "#Looping the null value column\n",
        "for col in high_null:\n",
        "  median_imputation(df1,col)\n",
        "\n",
        "#Mode to be used in place of null value in traveller type\n",
        "df1['cabin'].fillna(df1['cabin'].mode().values[0],inplace=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "vStwJgnmsFeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.head(1)"
      ],
      "metadata": {
        "id": "DAlXGh0-kHDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now no Nan value is present in any of the columns"
      ],
      "metadata": {
        "id": "gMs9EoZorF-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now to check how many missing values are in each column\n",
        "missi_value = df1.isnull().sum().sort_values(ascending=False)\n",
        "missi_value\n",
        "#Our Data is now well maintained and clean ready for visualization and ML algorithms"
      ],
      "metadata": {
        "id": "feII2XtE-f39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "__ Firstly,we remove the missing values from our major columns that are going to be used for our Visualization and ML model\n",
        "\n",
        "__ Then we drop unnecessary columns that are of no use in data Visualization as well as ML model\n",
        "\n",
        "__Then we Split the Numeric Column by splitting the columns into two lists, low_null and high_null, which contain the names of columns in a DataFrame that need imputation.\n",
        "\n",
        "__Then we name function impute_by_q1_values is defined for imputing missing values in specific columns using the Q1 value (the 25th percentile).\n",
        "\n",
        "__Then after ,Looping through Columns for Low Null Values:\n",
        "\n",
        "__Then we use Imputation Technique using Median Imputation\n",
        "\n",
        "__We name function median_imputation is defined for imputing missing values in specific columns using the median value.\n",
        "\n",
        "__Now this time for Looping Through Columns for High Null Values\n",
        "\n",
        "__Another loop iterates through the columns listed in high_null.\n",
        "\n",
        "__Finally,we use mode in place of missing values in Cabin Column."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1\n",
        "\n",
        "Which type of Cabin has more value for money?"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "#setting the figure size and plotting the graph\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(data=df1, x='cabin', hue='value_for_money')\n"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Airlines need to know which type of cabin is worth investing of according to passenger review."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see clearly in Econonmy class passenger gives highest rating and lowest too on the other hand passenger travelling in business class believes it is worth of money."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2\n",
        "Which Airline have more recommendation?"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "# Get the number of trips each airline make.\n",
        "recommendation_airlines =df1['airline'].value_counts()\n",
        "\n",
        "plt.figure(figsize=(10,5),facecolor=\"skyblue\")\n",
        "recommendation_airlines[:10].plot(kind='bar',color = 'pink')\n",
        "plt.xlabel('Airline Type',fontsize=12)\n",
        "plt.ylabel('recommended',fontsize=12)\n",
        "plt.title('highest recommendation ',fontsize=15)\n",
        "plt.xticks(rotation=90)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It shows comprehensive data which Airlines are more recommended by passengers."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spirit Airlines is highly recommended by passengers followed by british airways then china southern airlines."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3\n",
        "\n",
        "Average rating given by passenger across all types of cabin"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "df1=df1.groupby('cabin')[['food_bev','entertainment']].mean().reset_index()\n",
        "df1\n"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure('figsize'==(10,7))\n",
        "df1.plot(x=\"cabin\", y=[\"food_bev\", \"entertainment\"], kind=\"bar\",color=[\"skyblue\", \"pink\"])"
      ],
      "metadata": {
        "id": "t2_m0ZrJB7XQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This graph shows the average rating given by passenger across all types of cabin to help Airline as well as other fellow passengers to invest accordingly and choose their cabin for future journey."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From this graph it is clearly visible that business class and first class passenger gives higher rating for food beverages and entertainment and lower for economy."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4\n",
        "Types of travellers across different Cabins."
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(x='traveller_type', hue='cabin', data=df1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chart Clearly explain the distribution of different travellers across different cabins"
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this chart it is clearly shown that business type of travellers most used business type of cabin and solo leisure picks economy type of cabin most among all other traveller type categories."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5\n",
        "Which Airlines have made highest trips."
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "airlines_trips =df1['airline'].value_counts()\n",
        "\n",
        "plt.figure(figsize=(20,5),facecolor = 'skyblue')\n",
        "airlines_trips[:10].plot(kind='bar',color = 'pink')\n",
        "plt.xlabel('Airline Type',fontsize=12)\n",
        "plt.ylabel('Counts',fontsize=12)\n",
        "plt.title('Highest trip by Airline ',fontsize=15)\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To check the market demand of top 10 Airlines that are in competition"
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clearly visible that Spirit Airlines made highest trips followed by British Airways and china Southern airlines"
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6\n",
        "Cabin type have more service rating."
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "# Define a custom color palette\n",
        "custom_palette = [\"lightblue\", \"lightgreen\", \"lightcoral\"]\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.boxplot(x=df['cabin'], y=df1['cabin_service'], hue=df1['recommended'], palette=custom_palette)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I want to show the corelation between cabin service to recommendation over different cabin type."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is clearly visible that when the cabin service is given full star rating i.e 5 out of 5 here recommendation is most likely to happen.\n",
        "\n",
        "First class Passengers are least likely to give the recommendation.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7\n",
        "\n",
        "Which Airline have high Cabin service rating."
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "airline_mean_ratings = df1.groupby('airline')['cabin_service'].mean().reset_index()\n",
        "\n",
        "# Select the top 10 airlines based on the sum of ratings\n",
        "top_10_airlines = airline_mean_ratings.nlargest(10, 'cabin_service')\n",
        "\n",
        "top_10_airlines"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "sns.set(style=\"whitegrid\")\n",
        "sns.pointplot(x=\"airline\", y=\"cabin_service\", data=top_10_airlines, ci=None, join=False)\n",
        "\n",
        "plt.xticks(rotation=45)\n",
        "plt.title(\"Mean of Cabin Service Ratings by Airline (Top 10)\")\n",
        "plt.xlabel(\"Airline\")\n",
        "plt.ylabel(\"Mean of Cabin Service Ratings\")\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qkpMYq0Hx-3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Airlines offering high service rating irrespective of Cabin type."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?\n"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "From the pintgraph clearly visible that Garuda Indonesia have close to 4.6 average rating which is highest followed by ANA All Nippon Airways."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8\n",
        "\n",
        "Which Airline is most value for money."
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "airline_mean_ratings = df1.groupby('airline')['value_for_money'].mean().reset_index()\n",
        "top_10_airlines = airline_mean_ratings.nlargest(15, 'value_for_money')\n",
        "top_10_airlines"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "sns.set(style=\"darkgrid\")  # Set the background style\n",
        "custom_palette = sns.color_palette(\"Set3\", len(df1['airline'].unique()))\n",
        "sns.violinplot(data=top_10_airlines, x=\"airline\", y=\"value_for_money\", palette=custom_palette)\n",
        "\n",
        "plt.xticks(rotation=90)\n",
        "plt.title(\"Distribution of Value for Money Ratings by top 15 Airline\")\n",
        "plt.xlabel(\"Airline\")\n",
        "plt.ylabel(\"Value for Money Rating\")\n",
        "plt.tight_layout()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sLlQRt8z3gTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find out which airline offers high value for money."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chart Depicts EVA Air is high value for money as its average rating is 4.4 followed by china Southern Airlines"
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9\n",
        "Type of travellers doing most trips."
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.set(style=\"whitegrid\")  # Set the background style\n",
        "\n",
        "# Create a histogram (histplot) for the 'traveller_type' column\n",
        "sns.histplot(data=df1, x=\"traveller_type\", kde=True, color=\"blue\")\n",
        "\n",
        "plt.title(\"Distribution of Traveller Types\")\n",
        "plt.xlabel(\"Traveller Type\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find out which type of travellers made highest trips"
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clearly Visible that people likely to prefer solo trips."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.heatmap(df1.corr(), annot=True)"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "df1['traveller_type'].fillna(method=\"ffill\",inplace=True)\n"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missi_value = df1.isnull().sum().sort_values(ascending=False)\n",
        "missi_value"
      ],
      "metadata": {
        "id": "q4dveUze30EO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "#converting recommended column\n",
        "df1['recommended'].replace({'yes':1,'no':0},inplace=True)"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.head(5)"
      ],
      "metadata": {
        "id": "G3gfODhm4tFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As recommendation is our target column need to apply ML Algorithms"
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "#Correlation plot\n",
        "plt.figure(figsize=(10,7))\n",
        "sns.heatmap(df1.corr(), annot=True)\n"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Removing Multicollinearity features\n",
        "\n",
        "def mult_col(X):\n",
        "\n",
        "   # Calculating VIF\n",
        "   vif = pd.DataFrame()\n",
        "   vif[\"variables\"] = X.columns\n",
        "   vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "\n",
        "   return(vif)"
      ],
      "metadata": {
        "id": "bV6Ajzk39uQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mult_col(df1[[i for i in df1.describe().columns if i not in ['recommended','value_for_money']]])"
      ],
      "metadata": {
        "id": "YiwhUkk8-OJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Dropping Airline coloumn as it has no further use\n",
        "df1.drop([\"airline\"], axis = 1, inplace = True)\n"
      ],
      "metadata": {
        "id": "dzqAS087BZSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Drop overall column as it has highest correlation value than others.\n",
        "df1.drop([\"overall\"], axis = 1, inplace = True)\n"
      ],
      "metadata": {
        "id": "VMnBxVvoDJtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining the dependent and independent variables\n",
        "\n",
        "#separating the dependent and independent variables\n",
        "y = df1['recommended']\n",
        "x = df1.drop(columns = 'recommended')\n",
        "\n",
        "x.columns"
      ],
      "metadata": {
        "id": "X1UXE-YZCTaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = pd.get_dummies(x)\n",
        "\n",
        "x.shape"
      ],
      "metadata": {
        "id": "fYMGiyieCr-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.head(3)"
      ],
      "metadata": {
        "id": "fgrTo_SECw6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"The Percentage of No labels of Target Variable is\",np.round(y.value_counts()[0]/len(y)*100))\n",
        "print(\"The Percentage of Yes labels of Target Variable is\",np.round(y.value_counts()[1]/len(y)*100))"
      ],
      "metadata": {
        "id": "TR7o5LiKDtyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split( x,y , test_size = 0.2, random_state = 42)\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "KwD33KVjEk0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Percentage of both labels('yes','no) is approximately equal. So no need of Handling Class Imbalance technique."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1\n",
        "\n",
        "**Logistic Regression**"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "#logistic regression fitting\n",
        "log_reg = LogisticRegression(fit_intercept=True, max_iter=10000)\n",
        "log_reg.fit(x_train, y_train)\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_reg.coef_"
      ],
      "metadata": {
        "id": "uxBZ7Ks2EuY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_reg.intercept_"
      ],
      "metadata": {
        "id": "cYu9_7EhExdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "log_reg.score(x_test,y_test)"
      ],
      "metadata": {
        "id": "I1uVZbtZE00h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#94% accuracy with Logistic Regression"
      ],
      "metadata": {
        "id": "ZBQL8F8tE7KW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "y_pred = log_reg.predict(x_test)\n",
        "#report of logistic regression\n",
        "report_lR = classification_report(y_test, y_pred)\n",
        "print(report_lR)\n"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cofusion matrix of logistic regression\n",
        "confuse_matrix_lr = confusion_matrix( y_test,y_pred)\n",
        "#plooting confusion matrix\n",
        "sns.heatmap(confuse_matrix_lr, annot=True, fmt = \".1f\")"
      ],
      "metadata": {
        "id": "zwiyzxEOfYhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "logistic = LogisticRegression()\n",
        "\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "\n",
        "scores = cross_val_score(log_reg, x_train, y_train, cv=10)\n",
        "print('Cross-Validation Accuracy Scores', scores)\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "scores = pd.Series(scores)\n",
        "scores.min(), scores.mean(), scores.max()"
      ],
      "metadata": {
        "id": "uX0u48MDHYcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2\n",
        "\n",
        "\n",
        "\n",
        "**Decision Tree**"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "#Initializing Decision Tree Model object\n",
        "tree_classify=DecisionTreeClassifier()\n",
        "#Taining a model with x and y\n",
        "tree_classify.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Accuracy of Decision Tree Model is\",tree_classify.score(x_train,y_train))\n",
        "print(\"Testing Accuracy of Decision Tree Model is\",tree_classify.score(x_test,y_test))"
      ],
      "metadata": {
        "id": "MO9wh4rLIMT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_pred = tree_classify.predict(x_test)\n",
        "\n",
        "\n",
        "#report of decision tree\n",
        "report_dec_tree = classification_report(y_test, y_pred)\n",
        "print(report_dec_tree)\n"
      ],
      "metadata": {
        "id": "_so8mNJCIV7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#setting the parameters and scoring metric\n",
        "parameters = {\"criterion\":[\"gini\",\"entropy\"],\"max_depth\":[5,7],\"min_samples_split\":[5,7],\"min_samples_leaf\":[2,3]}\n",
        "scoring_=['f1','recall','precision','accuracy']\n",
        "\n",
        "\n",
        "#performing hyperparameter tuning using gridsearchcv\n",
        "\n",
        "#setting an estimator,and crossvalidation\n",
        "tree_cv = GridSearchCV(estimator=tree_classify, param_grid=parameters, scoring=scoring_, cv=5,refit='accuracy')\n",
        "\n",
        "#Fitting x and y to gridsearchcv model using an estimator Decision tree classifier\n",
        "tree_cv.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calling an best params\n",
        "tree_cv.best_params_\n"
      ],
      "metadata": {
        "id": "Smi0FWSYItRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calling our best score\n",
        "tree_cv.best_score_"
      ],
      "metadata": {
        "id": "PUNgVB79Iy0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#93% accuracy of Decision Tree with the help of hypermatring tunning."
      ],
      "metadata": {
        "id": "6eUUkyMZJG7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We Used Grid Search CV"
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3\n",
        "\n",
        "**Random Forest**"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model -\n",
        "\n",
        "# Fit the Algorithm\n",
        "random_forest = RandomForestClassifier()\n",
        "random_forest.fit(x_train,y_train)\n"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_forest.score(x_test,y_test)"
      ],
      "metadata": {
        "id": "wj7c52RSJbsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#report of decision tree\n",
        "report_ran_forest = classification_report(y_test, y_pred)\n",
        "print(report_ran_forest)"
      ],
      "metadata": {
        "id": "vJW-o5LpKfkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#92% accuracy with Random Forest"
      ],
      "metadata": {
        "id": "DuLL-DxoKhN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "random_forest_gridcv = GridSearchCV(estimator=random_forest,\n",
        "                       param_grid = parameters,\n",
        "                       cv = 5, verbose=2)\n",
        "\n",
        "\n",
        "random_forest_gridcv.fit(x_train,y_train)\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_forest_gridcv.best_params_"
      ],
      "metadata": {
        "id": "IpIuZ6PbLQ2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 4.ML Model\n",
        "\n",
        "\n",
        "**Support Vector Machine**"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "support_vector = SVC(kernel='linear')\n",
        "support_vector.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "dkwb-MZtMbVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#score for support vector machine\n",
        "support_vector.score(x_test, y_test)"
      ],
      "metadata": {
        "id": "1ey9C0nSM2xs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#94% accuracy with support vector machine"
      ],
      "metadata": {
        "id": "CC6w3k-fM6lI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = support_vector.predict(x_test)\n",
        "\n",
        "\n",
        "#confusion matrix\n",
        "support_vector_con_mat = confusion_matrix( y_test,y_pred)\n",
        "support_vector_con_mat"
      ],
      "metadata": {
        "id": "07sWbu6IM_KD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a function to return all Models Accuracy Score\n",
        "\n",
        "def accuracy_of_each_model(model,X_train,X_test):\n",
        "\n",
        "  #predicting a train datas\n",
        "  y_train_preds=model.predict(X_train)\n",
        "\n",
        "  #predicting a test datas\n",
        "  y_test_preds=model.predict(X_test)\n",
        "\n",
        "  #storing all training scores\n",
        "  train_scores=[]\n",
        "\n",
        "  #storing all test scores\n",
        "  test_scores=[]\n",
        "  metrics=['Accuracy_Score','Precsion_Score','Recall_Score','Roc_Auc_Score']\n",
        "\n",
        "  # Get the accuracy scores\n",
        "  train_accuracy_score = accuracy_score(y_train,y_train_preds)\n",
        "  test_accuracy_score = accuracy_score(y_test,y_test_preds)\n",
        "\n",
        "  train_scores.append(train_accuracy_score)\n",
        "  test_scores.append(test_accuracy_score)\n",
        "\n",
        "  # Get the precision scores\n",
        "  train_precision_score = precision_score(y_train,y_train_preds)\n",
        "  test_precision_score = precision_score(y_test,y_test_preds)\n",
        "\n",
        "  train_scores.append(train_precision_score)\n",
        "  test_scores.append(test_precision_score)\n",
        "\n",
        "  # Get the recall scores\n",
        "  train_recall_score =recall_score(y_train,y_train_preds)\n",
        "  test_recall_score =recall_score(y_test,y_test_preds)\n",
        "\n",
        "  train_scores.append(train_recall_score)\n",
        "  test_scores.append(test_recall_score)\n",
        "\n",
        "  # Get the roc_auc scores\n",
        "  train_roc_auc_score=roc_auc_score(y_train,y_train_preds)\n",
        "  test_roc_auc_score =roc_auc_score(y_test,y_test_preds)\n",
        "\n",
        "  train_scores.append(train_roc_auc_score)\n",
        "  test_scores.append(test_roc_auc_score)\n",
        "\n",
        "  return train_scores,test_scores,metrics\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "models=[log_reg,tree_cv,random_forest,support_vector]\n",
        "name=['Logistic Regression Model','Decision Tree Model After Hyperparameter Tuning','Random Forest Model After Hyperparameter Tuning','support vector',]\n",
        "\n",
        "\n",
        "for model_ in range(len(models)):\n",
        "  train_score_,test_score_,metrics_=accuracy_of_each_model(models[model_],x_train,x_test)\n",
        "  print(\"-*-*-\"*3+f\"{name[model_]}\"+\"-*-*-\"*4)\n",
        "  print(\"\")\n",
        "  print(pd.DataFrame(data={'Metrics':metrics_,'Train_Score':train_score_,'Test_Score':test_score_}))\n",
        "  print(\"\")"
      ],
      "metadata": {
        "id": "vqz11m4mNkCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have used 4 ML Model for prediction of Airline by Passenger to their friends,colleagues,family and based on our Accuracy Score we can say that Logistic regression gives very high prediction among others."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importance = random_forest.feature_importances_\n",
        "\n",
        "#examine the feature importance values\n",
        "\n",
        "for feature_name, importance in zip(x_train.columns, feature_importance):\n",
        "    print(f\"{feature_name}: {importance}\")"
      ],
      "metadata": {
        "id": "AW0kIaiRhbWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?\n",
        "\n",
        "#These importance scores provide insights into which features had the most impact on the model's predictions firstly, **value_for_money** and **ground_service** are the most influential features, with importance scores of 0.3010 and 0.2403, respectively. Features like **seat_comfort** and **cabin_service** also have significant importance"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used 4 Models for this classification problem are\n",
        "\n",
        "Logistic Regression Model,\n",
        "Decision Tree Model,\n",
        "Random Forest Model,\n",
        "Support Vector Machines\n",
        "\n",
        "I performed Hyperparameter tuning using Gridsearch CV method for Decision Tree Model, Random Forest Model  and Support Vector Machine To increase accuracy and avoid Overfitting Criteria, this is done. After that, we finalized the Gradient Boosting model by fine-tuning the hyperparameters.\n",
        "\n",
        "Based on the knowledge of the business and the problem usecase. The Classification metrics of Recall is given first priority , Accuray is given second priority , and ROC AUC is given third priority.\n",
        "\n",
        "I have built classifier models using 4 different types of classifiers and all these are able to give accuracy of more than 93%. I can conclude that Random Forest gives the best model.\n",
        "\n",
        "Model evaluation metrics comparison, we can see that Support Vector Machine being the model with highest accuracy rate by a very small margin, works best among the experimented models for the given dataset.\n",
        "\n",
        "The most important feature are overall rating and Value for money that contribute to a model's prediction whether a passenger will recommened a particular airline to his/her friends.\n",
        "\n",
        "The classifier models developed can be used to predict passenger referral as it will give airlines ability to identify impactful passengers who can help in bringing more revenues.\n",
        "\n",
        "\n",
        "As a result, in order to increase their business or grow, our client must provide excellent cabin service, ground service, food beverage entertainment, and seat comfort.\n"
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}